In DevOps, Kubernetes(k8's) in Realtime Senario Interview Questions and Answers:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. How do you think the company should shift it from Monolithic to Microservices?

2. Can you explain the Overview of Kubernetes Architecture?

3. Difference between Kubernetes and Docker Swarm for container orchestration?

4. What methods are available to expose Kubernetes services to external users, and how do they differ?

5. How would you deploy an application in Kubernetes to ensure zero downtime during updates?

6. Can you explain the difference between stateful and stateless applications, and how each is managed in Kubernetes?

7. How do you handle persistent data in Kubernetes, and what are Persistent Volumes (PVs) and Persistent Volume Claims (PVCs)?

8. Describe the process of scaling applications in Kubernetes both horizontally and vertically?

9. What are ConfigMaps and Secrets in Kubernetes, and how are they used?

10. How can you perform a rollback of a failed deployment in Kubernetes?

11. What tools and practices would you use to monitor a Kubernetes cluster and collect logs?

12. How do you implement security measures within a Kubernetes cluster?

13. Explain Kubernetes RBAC?

14. What is a Helm Chart, and how does it facilitate application deployment in Kubernetes?

15. How does Kubernetes use custom namespaces to organize cluster resources?

16. What are liveness and readiness probes in Kubernetes, and how are they used?

17. What is a Kubernetes network policy, and how does it work?

18. What is the difference between a Kubernetes Deployment and a DaemonSet?

19. How does ingress help in Kubernetes?

20. What is a Kubernetes Custom Resource Definition (CRD), and how can it be used to extend Kubernetes functionality?

21. What is the purpose of Operators?
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. How do you think the company should shift it from Monolithic to Microservices? 

EXPLAIN IN THIS ANSWER:-
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ‘‰ Monolithic Architecture is Everything built a single unit(code base), tightly coupled like different application(front-end,backend,DB)
   run as single code base.
   Itâ€™s simple to develop but hard to scalability â€”any change requires again will do redeploying the entire system.

ğŸ‘‰ Microservices Architecture breaks the application into independent services, 
   each handling a specific function and communicating via APIs. 
   Each service can be deployed, scaled, and updated separately, making it more flexible and better fault isolation.
------------------------------------------------------------------------------------------------------------------------------------------

2. Can you explain the Overview of Kubernetes Architecture?

EXPLAIN IN THIS ANSWER:-
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ‘‰ Kubernetes mainly consists of two components we can say one is MASTER NODE and second one is WORKER NODE.
   so in masternode inside there are four components..., So by the name we can understood from CM it is master node so it is 

1.Kube controller manager --> Manages the multiple process which are running masternode adn it is combined all the process together
                              and let in inform the MasterNode thats wt happening so it's basically manages all the process.

2.kube API-Server         --> Its acts as front end of MasterNode so it exposes all the API of k8s to MasterNode component and
                              is responsible for like creating communication between MasterNode and WorkerNode.

3.kube scheduler          --> Schedules like work for the WorkerNode as it inside MasterNode so it will schedule work for 
                              different WorkNodes.

4.etcd (database)         --> It's basically Key-Values to store like (username&password) so if we have to store it in this inside k8s
                              then we will mainly store it inside ETCD. 
                          ---> Okay these are 4 components which are MasterNode.

And comes into WokerNode inside there are two components..,

1.Kubelet     --> The Kubelet on that Worker Node communicates with the API Server to ensure the Pods are running.

2.Kube-Proxy  --> Kube Proxy ensures networking and allows to communication between Pods and Services.
              ---> So this the basic k8s architeture.
-----------------------------------------------------------------------------------------------------------------------------------------

3. Difference between Kubernetes and Docker Swarm for container orchestration?

EXPLAIN IN THIS ANSWER:-
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ‘‰ "Kubernetes and Docker Swarm are both container orchestration tools, but they different in complexity, scalability, and automation".

1. Kubernetes is a powerful orchestration tool and It will automatically self-healing, automated scaling, and advanced networking,
   making it perfect for large applications that need reliability and automation.

2.Docker Swarm is lightweight and easy to set up,it offers great for quick and simple deployments, 
  but it doesnâ€™t have the advanced automation and self-healing that compared to Kubernetes.
-----------------------------------------------------------------------------------------------------------------------------------------

4. What methods are available to expose Kubernetes services to external users, and how do they differ?

EXPLAIN IN THIS ANSWER:-
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ‘‰ In Kubernetes, a Service is a way to expose and manage network access to a set of Pods.

ğŸ‘‰ Pods are temporary and (they can be created and destroyed frequently), Services provide a stable way to communicate between applications.

There are four main types of services:

1ï¸âƒ£ ClusterIP (Default) â€“ Used for internal communication within the cluster.
2ï¸âƒ£ NodePort            â€“ Exposes services externally on a fixed port of each Node.
3ï¸âƒ£ LoadBalancer        â€“ Uses a cloud providerâ€™s load balancer(AWS) to distribute external traffic with a public IP.
4ï¸âƒ£ ExternalName        â€“ Maps to an external service (e.g., AWS RDS, external APIs)."one domain to another domain"
-----------------------------------------------------------------------------------------------------------------------------------------

5. How would you deploy an application in Kubernetes to ensure zero downtime during updates?

EXPLAIN IN THIS ANSWER:-
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… "To ensure zero downtime while updating an application in Kubernetes,
   I would use a "Rolling Update strategy" with Deployments". Hereâ€™s how it works and steps to explain:

ğŸ”¹ "Can you explain the process of a Rolling Update Strategy"
ğŸ‘‰ "A rolling update allows Kubernetes to update applications without downtime by gradually replacing old pods with new ones. 
    It ensures minimal disruption to users and can automatically roll back if the update fails."

1ï¸âƒ£ Define a Deployment with a specified replica count to ensure multiple pods are running.
2ï¸âƒ£ Use RollingUpdate strategy (default for Deployments) to gradually replace old pods with new ones.
3ï¸âƒ£ Set maxUnavailable=0 (ensures at least the current number of replicas remain available).
4ï¸âƒ£ Set maxSurge=1 or more (allows extra pods to start before terminating old ones).
5ï¸âƒ£ Use Readiness Probes to ensure new pods are only added to the service when theyâ€™re fully ready.
6ï¸âƒ£ Use Liveness Probes to monitor pod health and prevent serving broken pods.
7ï¸âƒ£ If an update fails, I can quickly rollback the deployment using:
ğŸ‘‰ kubectl rollout undo deployment <deployment-name>
ğŸ’¡ Example Deployment:
strategy:
  type: RollingUpdate
  rollingUpdate:
    maxUnavailable: 0
    maxSurge: 1
ğŸ”¥ "This ensures that users never experience downtime during updates!"
-----------------------------------------------------------------------------------------------------------------------------------------

6. Can you explain the difference between stateful and stateless applications, and how each is managed in Kubernetes?

EXPLAIN IN THIS ANSWER:-
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
In Kubernetes, applications can be either stateless or stateful,
and they are managed differently based on their data handling requirements.

ğŸ”¹ Stateless Applications:
ğŸ‘‰ Stateless applications are ones that donâ€™t need to remember anything from one request to the next request. 
   Each request is completely independent. So, once a request is finished, all the data is discarded. 
   For example, like (web servers"NGINX,APACHE" or APIs services), where the server doesn't need to remember previous interactions. 
   In Kubernetes, we manage these with Deployments because we can easily scale themâ€”if one pod fails, 
   it can be replaced without any issues. The new pod doesnâ€™t need to know about the old one.

ğŸ”¹ Stateful Applications:
ğŸ‘‰ Stateful applications, on the other hand, need to remember data between requests. 
   So, even if the pod is restarted, it should still have access to its previous data. 
   Examples include databases (e.g., MySQL, MongoDB), message queues, and other systems that maintain state between requests. 
   In Kubernetes handles these using StatefulSets, which ensures each pod gets a unique identity, 
   and we can attach persistent storage (like Persistent Volumes) so the data doesnâ€™t get lost. 
   This makes sure that even if the pod restarts, it can still find the same data.

ğŸ’¡ In simple terms:
ğŸ‘‰ Stateless apps donâ€™t store data between requests and are handled by Deployments.
ğŸ‘‰ Stateful apps store data and need StatefulSets and persistent storage to function properly.
-----------------------------------------------------------------------------------------------------------------------------------------

7. How do you handle persistent data in Kubernetes, and what are Persistent Volumes (PVs) and Persistent Volume Claims (PVCs)?

EXPLAIN IN THIS ANSWER:-
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"In Kubernetes, when we need to store data that should not be lost even if a pod restarts, 
we use Persistent Volumes (PVs) and Persistent Volume Claims (PVCs).

ğŸ”¹ Persistent Volume (PV) â€“ A storage resource in the cluster that is provisioned by an admin or dynamically created. 
   It acts like a hard drive that Kubernetes can use.

ğŸ”¹ Persistent Volume Claim (PVC) â€“ A request made by a pod to use storage resource. 
   The pod doesnâ€™t directly ask for a disk; instead, it asks for a PVC, and Kubernetes matches it with an available PV.

How Persistent Storage Works in Kubernetes:
1ï¸âƒ£ Create a PV â€“ Defines storage (e.g., EBS in AWS, NFS, Ceph, etc.).
2ï¸âƒ£ Create a PVC â€“ A pod requests storage by creating a claim.
3ï¸âƒ£ Pod uses the PVC â€“ Kubernetes binds the PVC to a suitable PV, and the pod gets persistent storage.
4ï¸âƒ£ Even if the pod restarts, the data remains because it is stored outside the pod.

ğŸ’¡ Example: Imagine a MySQL database running in Kubernetes. If the pod restarts without persistent storage, all data is lost. 
   But with a PVC attached to a PV, the database can retain its data across restarts.
   So, PVs provide actual storage, and PVCs let pods claim that storage. This ensures data persistence in Kubernetes!"
-----------------------------------------------------------------------------------------------------------------------------------------

8. Describe the process of scaling applications in Kubernetes both horizontally and vertically?

EXPLAIN IN THIS ANSWER:-
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"In Kubernetes, there are two ways to scale an application: Horizontally and Vertically".

1ï¸âƒ£ Horizontal Scaling (Scaling Out/In):
ğŸ‘‰ This means adding or removing pods to handle varying loads.
ğŸ‘‰ Kubernetes does this automatically using the Horizontal Pod Autoscaler (HPA).
ğŸ‘‰ HPA monitors metrics like CPU or memory usage and scales pods up or down as needed.

ğŸ’¡ Example command to manually scale:
kubectl scale deployment my-app --replicas=5
ğŸ’¡ Example HPA configuration:
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: my-app-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: my-app
  minReplicas: 2
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        targetAverageUtilization: 70

2ï¸âƒ£ Vertical Scaling (Scaling Up/Down):
ğŸ‘‰ This means increasing or decreasing CPU/RAM for existing pods instead of adding more pods.
ğŸ‘‰ Managed by Vertical Pod Autoscaler (VPA).
ğŸ‘‰ It adjusts resource requests/limits dynamically based on workload needs.

ğŸ’¡ Example VPA configuration:
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: my-app-vpa
spec:
  targetRef:
    apiVersion: "apps/v1"
    kind: "Deployment"
    name: "my-app"
  updatePolicy:
    updateMode: "Auto"
-----------------------------------------------------------------------------------------------------------------------------------------

9. What are ConfigMaps and Secrets in Kubernetes, and how are they used?

EXPLAIN IN THIS ANSWER:-
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"In Kubernetes, ConfigMaps and Secrets are used to store configuration data separately from application code, 
 making applications more flexible and secure."

ğŸ”¹ ConfigMaps (For Non-Sensitive Data):
ğŸ‘‰ Stores non-sensitive configuration data such as environment variables, config files, or command-line arguments.
ğŸ‘‰ Helps keep applications configurable without changing container images.
ğŸ‘‰ Example use case: Storing database connection URLs, API keys (if not sensitive), or log levels.

ğŸ’¡ Example ConfigMap YAML:
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-config
data:
  database_url: "mysql://db-service:3306"
  log_level: "debug"

ğŸ’¡ Using a ConfigMap in a Pod:
env:
  - name: DATABASE_URL
    valueFrom:
      configMapKeyRef:
        name: my-config
        key: database_url

ğŸ”¹ Secrets (For Sensitive Data)
ğŸ‘‰ Stores confidential data like passwords, API keys, TLS certificates.
ğŸ‘‰ Data is base64-encoded (not encrypted, so use RBAC to protect it).
ğŸ‘‰ Example use case: Storing database passwords, authentication tokens, or SSH keys.

ğŸ’¡ Example Secret YAML:
apiVersion: v1
kind: Secret
metadata:
  name: my-secret
type: Opaque
data:
  db_password: cGFzc3dvcmQ=   # (base64 encoded "password")

ğŸ’¡ Using a Secret in a Pod:
env:
  - name: DB_PASSWORD
    valueFrom:
      secretKeyRef:
        name: my-secret
        key: db_password
-----------------------------------------------------------------------------------------------------------------------------------------

10. How can you perform a rollback of a failed deployment in Kubernetes?

EXPLAIN IN THIS ANSWER:-
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"In Kubernetes, if a deployment update fails, we can easily roll back to a previous stable version using kubectl rollout undo."

ğŸ”¹ Steps to Perform a Rollback
1ï¸âƒ£ Check the Deployment History
ğŸ‘‰ kubectl rollout history deployment <deployment-name>
ğŸ’¡ This shows the revision history of the deployment.

2ï¸âƒ£ Rollback to the Previous Version
ğŸ‘‰ kubectl rollout undo deployment <deployment-name>
ğŸ’¡ This reverts the deployment to the last working state.

3ï¸âƒ£ Rollback to a Specific Revision (if needed)
ğŸ‘‰ kubectl rollout undo deployment <deployment-name> --to-revision=2
ğŸ’¡ This allows you to roll back to a specific version from the history.

4ï¸âƒ£ Check the Status After Rollback
ğŸ‘‰ kubectl get pods
ğŸ‘‰ kubectl describe deployment <deployment-name>
ğŸ’¡ Ensure the rollback was successful and pods are running correctly.

ğŸ”¹ Example Use Case:-
"Imagine you deployed a new version of an application, but it caused downtime. 
 Instead of debugging immediately, you quickly roll back to the previous working version to restore service, 
 then troubleshoot the issue separately."
" It helps maintain high availability and quick recovery from failures."
-----------------------------------------------------------------------------------------------------------------------------------------

11. What tools and practices would you use to monitor a Kubernetes cluster and collect logs?

EXPLAIN IN THIS ANSWER:-
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ”¹ Monitoring Tools & Practices
âœ… Prometheus + Grafana (Most Common)
ğŸ‘‰ Prometheus: Collects metrics from Kubernetes (CPU, memory, network, etc.).
ğŸ‘‰ Grafana: Visualizes the metrics with dashboards.
ğŸ‘‰ How it works? Prometheus scrapes metrics from Kubernetes components and Grafana displays them.

ğŸ’¡ Command to check resource usage:
kubectl top pod
kubectl top node

ğŸ”¹ Logging Tools & Practices
âœ… Fluentd + Elasticsearch + Kibana (EFK Stack)
ğŸ‘‰ Fluentd: Collects logs from Kubernetes pods.
ğŸ‘‰ Elasticsearch: Stores and indexes logs.
ğŸ‘‰ Kibana: Provides a UI to search and analyze logs.

ğŸ’¡ Check logs of a pod:
kubectl logs <pod-name>
ğŸ’¡ Check logs of a pod running multiple containers:
kubectl logs <pod-name> -c <container-name>
ğŸ’¡ Stream logs in real-time:
kubectl logs -f <pod-name>

ğŸ”¹ "For monitoring, we use Prometheus & Grafana, and for logging, we use the EFK or Loki stack. 
These tools help track cluster health, troubleshoot issues, and ensure smooth operations in Kubernetes."
-----------------------------------------------------------------------------------------------------------------------------------------

12. How do you implement security measures within a Kubernetes cluster?

EXPLAIN IN THIS ANSWER:-
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1ï¸âƒ£ RBAC (Role-Based Access Control) â€“ Restricts user and service access based on roles.
2ï¸âƒ£ Network Policies â€“ Controls pod-to-pod and external communication, preventing unauthorized access within the cluster.
3ï¸âƒ£ Container Security â€“ Ensures containers are running securely by using image scanning tools (like Trivy).
4ï¸âƒ£ Secrets Management â€“ Stores sensitive data (like API keys and passwords), securely using Kubernetes Secrets 
   instead of plain text environment variables.
5ï¸âƒ£ Audit Logging â€“ Tracks all Kubernetes API activities, helping detect and respond to security incidents.
6ï¸âƒ£ Update & Patching â€“ Regularly updating Kubernetes components, nodes, and dependencies to prevent vulnerabilities.

ğŸ”¹ "These measures provide a solid foundation for securing Kubernetes clusters."
-----------------------------------------------------------------------------------------------------------------------------------------
13. Explain Kubernetes RBAC?

EXPLAIN IN THIS ANSWER:-
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ‘‰ RBAC (Role-Based Access Control) in Kubernetes restricts access to resources based onuser roles.
   You define Roles with specific permissions (e.g., create, delete) and bind them to users or groups using RoleBindings.
   RBAC ensures users and applications have access only to necessary resources, 
   following the principle of least privilege and enhancing security.
-----------------------------------------------------------------------------------------------------------------------------------------

14. What is a Helm Chart, and how does it facilitate application deployment in Kubernetes?

EXPLAIN IN THIS ANSWER:-
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ‘‰ "A Helm Chart is a package that contains all the Kubernetes resources needed to deploy an application, 
   such as Deployments, Services, and ConfigMaps. 
   It simplifies the process by allowing you to deploy an entire application with a single command. 
   Helm charts can be customized with a values.yaml file, like replicas, resource limits, etc,,.
   and they support versioning, making it easy to manage updates and rollbacks of applications in Kubernetes."
-----------------------------------------------------------------------------------------------------------------------------------------

15. How does Kubernetes use custom namespaces to organize cluster resources?

EXPLAIN IN THIS ANSWER:-
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ‘‰ "In Kubernetes, namespaces are used to organize and isolate resources within a cluster. 
   They provide a way to divide cluster resources into different environments, teams, or applications 
   This makes it easier to manage and maintain your resources within the cluster,
   and also provides better security and resource isolation, while ensuring they donâ€™t interfere with each other."
-----------------------------------------------------------------------------------------------------------------------------------------

16. What are liveness and readiness probes in Kubernetes, and how are they used?

EXPLAIN IN THIS ANSWER:-
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ”¹ Liveness Probe:
ğŸ‘‰ Purpose: Checks if the application is alive and running.
ğŸ‘‰ If the liveness probe fails, Kubernetes will restart the container, assuming the app is in a broken or unresponsive state.
ğŸ‘‰ Use case: For detecting situations where your app is stuck or deadlocked.

ğŸ’¡ Example:
ğŸ‘‰ You can set up a liveness probe to check if your app responds on a specific endpoint (like /healthz),
   if the app doesnâ€™t respond correctly, Kubernetes will restart it.
livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
  initialDelaySeconds: 5
  periodSeconds: 10

ğŸ”¹ Readiness Probe:
ğŸ‘‰ Purpose: Checks if the application is ready to serve traffic.
ğŸ‘‰ If the readiness probe fails, Kubernetes will stop routing traffic to the pod until it becomes healthy again, 
   but it wonâ€™t restart the container.
ğŸ‘‰ Use case: For detecting if your app is still starting up or temporarily unable to serve requests,
   (e.g., during a database migration or a heavy load).

ğŸ’¡ Example:
A readiness probe can be configured to check if the database is ready before allowing the app to accept traffic.
readinessProbe:
  httpGet:
    path: /readiness
    port: 8080
  initialDelaySeconds: 10
  periodSeconds: 15
-----------------------------------------------------------------------------------------------------------------------------------------

17. What is a Kubernetes network policy, and how does it work?

EXPLAIN IN THIS ANSWER:-
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ‘‰ "A Kubernetes Network Policy is a way to control the communication between pods, services, and external resources.
   It defines which pods can communicate with each other and which cannot, based on a set of rules."

ğŸ”¹ Key Concepts
1ï¸âƒ£ Default Behavior (Before Network Policies)
ğŸ‘‰ By default, Kubernetes allows all pod-to-pod communication within a cluster.
ğŸ‘‰ No restrictions unless you explicitly configure them.

2ï¸âƒ£ Purpose of Network Policies
ğŸ‘‰ To restrict traffic to specific pods or services.
ğŸ‘‰ Enhance security by controlling which pods can talk to each other.

3ï¸âƒ£ How It Works
ğŸ‘‰ A network policy defines a set of rules that allow or deny traffic to/from pods based on labels, namespaces, ports, and IP blocks.
ğŸ‘‰ If a policy is applied, it restricts traffic to only what is allowed by the policy and blocks anything not explicitly allowed.

4ï¸âƒ£ Network Policy Selector
ğŸ‘‰ PodSelector: Selects the pods that are affected by the policy (e.g., all pods with label app: frontend).
ğŸ‘‰ Ingress and Egress Rules: Controls incoming and outgoing traffic.

ğŸ”¹ Types of Network Policies:-
ğŸ‘‰ Ingress Policies: Controls incoming traffic to a pod.
ğŸ‘‰ Egress Policies: Controls outgoing traffic from a pod.
-----------------------------------------------------------------------------------------------------------------------------------------

18. What is the difference between a Kubernetes Deployment and a DaemonSet?

EXPLAIN IN THIS ANSWER:-
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ”¹ Kubernetes Deployment:
ğŸ‘‰ Purpose: Manages a replicated application that needs to run in multiple pods for scalability and high availability.
ğŸ‘‰ Behavior: Ensures that a specified number of replicas of a pod are running at any given time. 
   It provides automated rollouts, scaling, and rollback capabilities.
ğŸ‘‰ Ideal for stateless applications where you want multiple copies of your app running for high availability.

ğŸ”¹ Kubernetes DaemonSet
ğŸ‘‰ Purpose: Ensures that a copy of a pod is running on every node (or a subset of nodes) in the cluster.
ğŸ‘‰ Behavior: Automatically creates a pod on each node in the cluster, ensuring that a single instance of the pod runs on each node.
ğŸ‘‰ No scaling involved â€” there will always be one pod per node.

ğŸ‘‰ "A Kubernetes Deployment ensures a specified number of replicas of a pod are running, ideal for stateless applications." 
ğŸ‘‰ "A DaemonSet ensures that a pod runs on every node in the cluster, making it ideal for system-level tasks like monitoring or logging."
-----------------------------------------------------------------------------------------------------------------------------------------

19. How does ingress help in Kubernetes?

EXPLAIN IN THIS ANSWER:-
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ‘‰ "Ingress in Kubernetes is used to manage external access to the services inside the cluster, typically HTTP/S traffic. 
   It provides features like load balancing, SSL termination, and path-based or host-based routing. 
   Ingress helps simplify service exposure by providing a single entry point and managing traffic routing efficiently, 
   improving scalability and security in your cluster."
-----------------------------------------------------------------------------------------------------------------------------------------

20. What is a Kubernetes Custom Resource Definition (CRD), and how can it be used to extend Kubernetes functionality?

EXPLAIN IN THIS ANSWER:-
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ‘‰ "A Kubernetes Custom Resource Definition (CRD) allows you to define custom resources in your cluster, 
   extending Kubernetes with new resource types. 
   CRDs are commonly used with controllers or operators to automate complex tasks and manage application-specific resources.
   This gives you the flexibility to build Kubernetes-native solutions for your needs, 
   while maintaining the benefits of Kubernetes' declarative configuration and scalability."
-----------------------------------------------------------------------------------------------------------------------------------------

21. What is the purpose of Operators?

EXPLAIN IN THIS ANSWER:-
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ‘‰ "A Kubernetes operator is a method of packaging, deploying, and managing a Kubernetes application.
   An operator uses the Kubernetes API to automate tasks such as deployment,
   scaling, implementing custom controllers, enabling self-healing systems, and supporting declarative management practices."

ğŸ‘‰ "For example, the Prometheus Operator automates the deployment and management of
   Prometheus monitoring instances on Kubernetes, handling tasks such as configuration,
   scaling, and self-healing, thereby simplifying the monitoring of Kubernetes clusters."
-----------------------------------------------------------------------------------------------------------------------------------------

























