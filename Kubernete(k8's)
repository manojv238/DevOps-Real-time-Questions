In DevOps, Kubernetes(k8's) in Realtime Senario Interview Questions and Answers:
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
1. How do you think the company should shift it from Monolithic to Microservices?

2. Can you explain the Overview of Kubernetes Architecture?

3. Difference between Kubernetes and Docker Swarm for container orchestration?

4. What methods are available to expose Kubernetes services to external users, and how do they differ?

5. How would you deploy an application in Kubernetes to ensure zero downtime during updates?"(Rolling upadate Stratagy)"

6. Can you explain the difference between stateful and stateless applications, and how each is managed in Kubernetes?

7. How do you handle persistent data in Kubernetes, and what are Persistent Volumes (PVs) and Persistent Volume Claims (PVCs)?

8. Describe the process manually of scaling applications in Kubernetes both horizontally and vertically?

9. What are ConfigMaps and Secrets in Kubernetes, and how are they used?

10. How can you perform a rollback of a failed deployment in Kubernetes?

11. What tools and practices would you use to monitor a Kubernetes cluster and collect logs?

12. How do you implement security measures within a Kubernetes cluster?

13. Explain Kubernetes RBAC?

14. What is a Helm Chart, and how does it facilitate application deployment in Kubernetes?

15. How does Kubernetes use custom namespaces to organize cluster resources?

16. What are liveness and readiness probes in Kubernetes, and how are they used?

17. What is a Kubernetes network policy, and how does it work?

18. What is the difference between a Kubernetes Deployment and a DaemonSet?

19. How does ingress help in Kubernetes?

20. What is a Kubernetes Custom Resource Definition (CRD), and how can it be used to extend Kubernetes functionality?

21. What is the purpose of Operators?

22. You have a Kubernetes pod that is stuck in CrashLoopBackOff . How do you diagnose and fix it?

23. You need to restrict access to a Kubernetes service based on labels. How do you achieve this?

24. You want to upgrade a deployment to a new version. How do you perform a rolling update in Kubernetes?

25. You want to increase the memory limit of a pod. How do you modify the pod's resource limits?

26.  You want to limit the CPU and memory usage for a container. How do you set resource requests and limits?

27. You have a Kubernetes cluster with multiple worker nodes. One of the nodes becomes unresponsive and needs to be replaced. 
    Explain the steps you would take to replace the node without affecting the availability of applications running on the cluster?

28.  A Kubernetes pod is stuck in a "Pending" state. What could be the possible reasons, and how would you troubleshoot it?

29.  You have a Kubernetes Deployment with multiple replicas, and some pods arefailing health checks. 
     How would you identify the root cause and fix it?
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

1. How do you think the company should shift it from Monolithic to Microservices? 

EXPLAIN IN THIS ANSWER:-
━━━━━━━━━━━━━━━━━━━━━━━━
👉 Monolithic Architecture is Everything built a single unit(code base), tightly coupled like different application(front-end,backend,DB)
   run as single code base.
   It’s simple to develop but hard to scalability —any change requires again will do redeploying the entire system.

👉 Microservices Architecture breaks the application into independent services, 
   each handling a specific function and communicating via APIs. 
   Each service can be deployed, scaled, and updated separately, making it more flexible and better fault isolation.
------------------------------------------------------------------------------------------------------------------------------------------

2. Can you explain the Overview of Kubernetes Architecture?

EXPLAIN IN THIS ANSWER:-
━━━━━━━━━━━━━━━━━━━━━━━━
👉 Kubernetes mainly consists of two components we can say one is MASTER NODE and second one is WORKER NODE.
   so in masternode inside there are four components..., So by the name we can understood from CM it is master node so it is 

1.Kube controller manager --> Manages the multiple process which are running masternode adn it is combined all the process together
                              and let in inform the MasterNode thats wt happening so it's basically manages all the process.

2.kube API-Server         --> Its acts as front end of MasterNode so it exposes all the API of k8s to MasterNode component and
                              is responsible for like creating communication between MasterNode and WorkerNode.

3.kube scheduler          --> Schedules like work for the WorkerNode as it inside MasterNode so it will schedule work for 
                              different WorkNodes.

4.etcd (database)         --> It's basically Key-Values to store like (username&password) so if we have to store it in this inside k8s
                              then we will mainly store it inside ETCD. 
                          ---> Okay these are 4 components which are MasterNode.

And comes into WokerNode inside there are two components..,

1.Kubelet     --> The Kubelet on that Worker Node communicates with the API Server to ensure the Pods are running.

2.Kube-Proxy  --> Kube Proxy ensures networking and allows to communication between Pods and Services.
              ---> So this the basic k8s architeture.
-----------------------------------------------------------------------------------------------------------------------------------------

3. Difference between Kubernetes and Docker Swarm for container orchestration?

EXPLAIN IN THIS ANSWER:-
━━━━━━━━━━━━━━━━━━━━━━━━
👉 "Kubernetes and Docker Swarm are both container orchestration tools, but they different in complexity, scalability, and automation".

1. Kubernetes is a powerful orchestration tool and It will automatically self-healing, automated scaling, and advanced networking,
   making it perfect for large applications that need reliability and automation.

2.Docker Swarm is lightweight and easy to set up,it offers great for quick and simple deployments, 
  but it doesn’t have the advanced automation and self-healing that compared to Kubernetes.
-----------------------------------------------------------------------------------------------------------------------------------------

4. What methods are available to expose Kubernetes services to external users, and how do they differ?

EXPLAIN IN THIS ANSWER:-
━━━━━━━━━━━━━━━━━━━━━━━━
👉 In Kubernetes, a Service is a way to expose services externally and manage network access to a set of Pods.
👉 Pods are temporary and (they can be created and destroyed frequently), 
    So we can use Services thats provide a stable way to communicate between applications.

1. ClusterIP is default internal cluster,
2. NodePort is simple but limited, 
3. LoadBalancer is best for cloud environments, and 
4. Ingress provides advanced routing with a single entry point. 
"For production, I prefer using Ingress with an Ingress Controller for better security, TLS termination, and traffic management."

SENARIO EXPLANATION ANSWER:-
━━━━━━━━━━━━━━━━━━━━━━━━━━━━
ClusterIP (Default) – Used for internal communication within the cluster.
1️⃣ NodePort (Basic, for Development & Testing):-
👉 Exposes the service on a static port (e.g., 30000-32767) on every worker node.
👉 Users access the service using NodeIP:NodePort.
✅ Example NodePort:
------------------------------------------------------------------------
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  type: NodePort
  selector:
    app: my-app
  ports:
    - port: 80           ### Internal service port
      targetPort: 8080   ### Container port
      nodePort: 30001    ### External access port

🔹 Access URL: http://<Node-IP>:30001
🔻 Limitations: Not recommended for production (port conflicts, security issues).

2️⃣ LoadBalancer (Best for Cloud Environment:-
👉 Allocates a cloud-managed load balancer (AWS ELB, Azure LB, GCP LB).
👉 Provides an external IP to distribute traffic across pods.
✅ Example LoadBalancer:
------------------------------------------------------------------------
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  type: LoadBalancer
  selector:
    app: my-app
  ports:
    - port: 80
      targetPort: 8080

🔹 Access URL: http://<External-IP>
🔻 Limitations: Only works in cloud environments, costs extra.

3️⃣ Ingress (Best for Routing & TLS)
👉 Uses a single entry point (Ingress Controller) to route traffic to multiple services.
👉 Supports TLS termination (HTTPS), load balancing, and path-based routing.
✅ Example Ingress Resource:
------------------------------------------------------------------------
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: my-ingress
spec:
  rules:
    - host: myapp.example.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: my-service
                port:
                  number: 80

🔹 Access URL: https://myapp.example.com
🔻 Limitations: Requires an Ingress Controller (NGINX, Traefik, Istio).
-----------------------------------------------------------------------------------------------------------------------------------------

5. How would you deploy an application in Kubernetes to ensure zero downtime during updates?

EXPLAIN IN THIS ANSWER:-
━━━━━━━━━━━━━━━━━━━━━━━━
✅ "To ensure zero downtime while updating an application in Kubernetes,
   I would use a "Rolling Update strategy" with Deployments". Here’s how it works and steps to explain:

🔹 "Can you explain the process of a Rolling Update Strategy"
👉 "A rolling update allows Kubernetes to update applications without downtime by gradually replacing old pods with new ones. 
    It ensures minimal disruption to users and can automatically roll back if the update fails."

1️⃣ Define a Deployment with a specified replica count to ensure multiple pods are running.
2️⃣ Use RollingUpdate strategy (default for Deployments) to gradually replace old pods with new ones.
3️⃣ Set maxUnavailable=1 (ensures at least 2 the current number of replicas remain available).
4️⃣ Set maxSurge=1 or more (allows extra pods to start before terminating old ones).
5️⃣ Use Readiness Probes to ensure new pods are only added to the service when they’re fully ready.
6️⃣ Use Liveness Probes to monitor pod health and prevent serving broken pods.
7️⃣ If an update fails, I can quickly rollback the deployment using:
👉 kubectl rollout undo deployment <deployment-name>
✅ Example Deployment:
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
🔥 "This ensures that users never experience downtime during updates!"
-----------------------------------------------------------------------------------------------------------------------------------------

6. Can you explain the difference between stateful and stateless applications, and how each is managed in Kubernetes?

EXPLAIN IN THIS ANSWER:-
━━━━━━━━━━━━━━━━━━━━━━━━
In Kubernetes, applications can be either stateless or stateful,
and they are managed differently based on their data handling requirements.

🔹 Stateless Applications:
👉 Stateless applications are ones that don’t need to remember anything from one request to the next request. 
   Each request is completely independent. So, once a request is finished, all the data is discarded. 
   For example, like (web servers"NGINX,APACHE" or APIs services), where the server doesn't need to remember previous interactions. 
   In Kubernetes, we manage these with Deployments because we can easily scale them—if one pod fails, 
   it can be replaced without any issues. The new pod doesn’t need to know about the old one.

🔹 Stateful Applications:
👉 Stateful applications, on the other hand, need to remember data between requests. 
   So, even if the pod is restarted, it should still have access to its previous data. 
   Examples include databases (e.g., MySQL, MongoDB), message queues, and other systems that maintain state between requests. 
   In Kubernetes handles these using StatefulSets, which ensures each pod gets a unique identity, 
   and we can attach persistent storage (like Persistent Volumes) so the data doesn’t get lost. 
   This makes sure that even if the pod restarts, it can still find the same data.

✅ In simple terms:
👉 Stateless apps don’t store data between requests and are handled by Deployments.
👉 Stateful apps store data and need StatefulSets and persistent storage to function properly.
-----------------------------------------------------------------------------------------------------------------------------------------

7. How do you handle persistent data in Kubernetes, and what are Persistent Volumes (PVs) and Persistent Volume Claims (PVCs)?

EXPLAIN IN THIS ANSWER:-
━━━━━━━━━━━━━━━━━━━━━━━━
"In Kubernetes, when we need to store data that should not be lost even if a pod restarts, 
we use Persistent Volumes (PVs) and Persistent Volume Claims (PVCs).

🔹 Persistent Volume (PV) – A storage resource in the cluster that is provisioned by an admin or dynamically created. 
   It acts like a hard drive that Kubernetes can use.

🔹 Persistent Volume Claim (PVC) – A request made by a pod to use storage resource. 
   The pod doesn’t directly ask for a disk; instead, it asks for a PVC, and Kubernetes matches it with an available PV.

How Persistent Storage Works in Kubernetes in pod:
1️⃣ Create a PV – Defines storage (e.g., EBS in AWS, NFS, etc.).
✅ Example PV YAML (for a local storage volume):
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: my-pv
spec:
  capacity:
    storage: 5Gi     ------------------------> Defines the storage capacity
  accessModes:
    - ReadWriteOnce  -------------------------> Defines how the volume can be accessed (RWO, RWX, ROX)
  persistentVolumeReclaimPolicy: Retain  -----> What happens when PVC is deleted (Retain, Recycle, Delete)
  storageClassName: manual  ------------------> Storage class that matches the PVC
  hostPath:
    path: "/mnt/data"    ---------------------> Path to local storage on the node
---------------------------------------------------------------------------------------
2️⃣ Create a PVC – A pod requests storage by creating a claim.
✅ Example PVC YAML:
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: my-pvc
spec:
  accessModes:
    - ReadWriteOnce  ------------> Should match PV access mode
  resources:
    requests:
      storage: 5Gi   ------------> Should match PV capacity
  storageClassName: manual ------> Must match the PV storage class
---------------------------------------------------------------------------------------
3️⃣ Attach the PVC to a Pod – Kubernetes binds the PVC to a suitable PV, and the pod gets persistent storage.
Example Pod using PVC:
---
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  volumes:
    - name: my-storage
      persistentVolumeClaim:
        claimName: my-pvc  ------> This references the PVC created earlier
  containers:
    - name: my-container
      image: nginx
      volumeMounts:
        - mountPath: "/usr/share/nginx/html"
          name: my-storage

👉 Even if the pod restarts, the data remains because it is stored outside the pod.

✅ Example: Imagine a MySQL database running in Kubernetes. If the pod restarts without persistent storage, all data is lost. 
    But with a PVC attached to a PV, the database can retain its data across restarts.
    So, PVs provide actual storage, and PVCs let pods claim that storage. This ensures data persistence in Kubernetes!"
-----------------------------------------------------------------------------------------------------------------------------------------

8. Describe the process manually of scaling applications in Kubernetes both horizontally and vertically?

EXPLAIN IN THIS ANSWER:-
━━━━━━━━━━━━━━━━━━━━━━━━
👉 "To manually scale a Kubernetes Deployment, I can use kubectl scale deployment <name> --replicas=<count> for horizontal scaling. 
    Alternatively, I can modify the Deployment YAML file and set the desired number of replicas. 
    If vertical scaling is needed, I update the CPU and memory requests/limits in the pod spec and apply the changes.
    This ensures efficient resource utilization based on workload demands."

👉 "In Kubernetes, there are two ways to scale an application: Horizontally and Vertically".
🔹 Horizontal Scaling (Increasing/Decreasing Replicas):-
1️⃣ used kubctl cmd To manually increase or decrease the number of replicas:
👉 kubectl scale deployment <deployment-name> --replicas=<desired-count>
✅ Example: Scale to 5 replicas
👉 kubectl scale deployment my-app --replicas=5
✅ To verify the scaling:
👉 kubectl get deployment my-app
2️⃣ Modify the replicas field in the Deployment YAML file:
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
spec:
  replicas: 5  ###### Change this value
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
      - name: my-app-container
        image: my-app-image:latest
---------------------------------------------------------------
Apply the changes:
👉 kubectl apply -f deployment.yaml

🔹 Vertical Scaling (Increasing CPU & Memory for Pods):-
1️⃣ Check Current Resource Limits
👉 kubectl describe deployment <deployment-name>
2️⃣ Update Resource Requests and Limits Modify the resources section in the Deployment YAML:
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
spec:
  replicas: 3
  template:
    spec:
      containers:
        - name: my-container
          image: my-app:v1
          resources:
            requests:
              memory: "512Mi"
              cpu: "250m"
            limits:
              memory: "1Gi"
              cpu: "500m"
----------------------------------------------------------
Apply the changes:
👉 kubectl apply -f deployment.yaml
-----------------------------------------------------------------------------------------------------------------------------------------

9. What are ConfigMaps and Secrets in Kubernetes, and how are they used?

EXPLAIN IN THIS ANSWER:-
━━━━━━━━━━━━━━━━━━━━━━━━
"In ConfigMaps and Secrets are used to store configuration data separately from application code, 
 making applications more flexible and secure."

🔹 ConfigMaps (For Non-Sensitive Data):
👉 Stores non-sensitive configuration data such as environment variables, config files, or command-line arguments.
👉 Helps keep applications configurable without changing container images.
👉 Example use case: Storing database connection URLs, API keys (if not sensitive), or log levels.
1️⃣ Example Create a ConfigMap from YAML:
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-config
data:
  APP_ENV: "production"
  LOG_LEVEL: "info"

Apply the ConfigMap:
👉 kubectl apply -f configmap.yaml
2️⃣ Using a ConfigMap in a Pod:
---
apiVersion: v1
kind: Pod
metadata:
  name: my-app
spec:
  containers:
    - name: my-container
      image: nginx
      envFrom:
        - configMapRef:
            name: my-config

👉 The pod loads environment variables APP_ENV=production and LOG_LEVEL=info from my-config.

🔹 Secrets (For Sensitive Data):
👉 Stores confidential data like passwords, API keys, TLS certificates.
👉 Data is base64-encoded (not encrypted, so use RBAC to protect it).
👉 Example use case: Storing database passwords, authentication tokens, or SSH keys.
1️⃣ Create a Secret from YAML:
---
apiVersion: v1
kind: Secret
metadata:
  name: my-secret
type: Opaque
data:
  db_password: cGFzc3dvcmQ=   ----> (base64 encoded "password")

Apply the Secret:
👉 kubectl apply -f secret.yaml

2️⃣ Use Secret in a Pod:
---
apiVersion: v1
kind: Pod
metadata:
  name: my-app
spec:
  containers:
    - name: my-container
      image: nginx
      env:
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: my-secret
              key: DB_PASSWORD

👉 The pod loads DB_PASSWORD from my-secret. It prevents hardcoding credentials in YAML files.
-----------------------------------------------------------------------------------------------------------------------------------------

10. How can you perform a rollback of a failed deployment in Kubernetes?

EXPLAIN IN THIS ANSWER:-
━━━━━━━━━━━━━━━━━━━━━━━━
"In Kubernetes, if a deployment update fails, we can easily roll back to a previous stable version using kubectl rollout undo."

🔹 Steps to Perform a Rollback
1️⃣ Check the Deployment History
👉 kubectl rollout history deployment <deployment-name>
💡 This shows the revision history of the deployment.

2️⃣ Rollback to the Previous Version
👉 kubectl rollout undo deployment <deployment-name>
💡 This reverts the deployment to the last working state.

3️⃣ Rollback to a Specific Revision (if needed)
👉 kubectl rollout undo deployment <deployment-name> --to-revision=2
💡 This allows you to roll back to a specific version from the history.

4️⃣ Check the Status After Rollback
👉 kubectl get pods
👉 kubectl describe deployment <deployment-name>
💡 Ensure the rollback was successful and pods are running correctly.

🔹 Example Use Case:-
"Imagine you deployed a new version of an application, but it caused downtime. 
 Instead of debugging immediately, you quickly roll back to the previous working version to restore service, 
 then troubleshoot the issue separately."
" It helps maintain high availability and quick recovery from failures."
-----------------------------------------------------------------------------------------------------------------------------------------

11. What tools and practices would you use to monitor a Kubernetes cluster and collect logs?

EXPLAIN IN THIS ANSWER:-
━━━━━━━━━━━━━━━━━━━━━━━━
👉 "For monitoring Kubernetes, I use Prometheus & Grafana to track CPU, memory, and pod health.
     For logging, I use ELK (Elasticsearch, Logstash, Kibana) to collect and analyze logs.
     I also set up alerts and structured logging for proactive issue detection. 
     This helps ensure cluster stability and quick troubleshooting."

🔹 Monitoring Tools & Practices
✅ Prometheus + Grafana (Most Common)
👉 Prometheus: Collects metrics from Kubernetes (CPU, memory, network, etc.).
👉 Grafana: Visualizes the metrics with dashboards.
👉 How it works? Prometheus scrapes metrics from Kubernetes components and Grafana displays them.

💡 Command to check resource usage:
kubectl top pod
kubectl top node

🔹 Logging Tools & Practices
✅ Fluentd + Elasticsearch + Kibana (EFK Stack)
👉 Fluentd: Collects logs from Kubernetes pods.
👉 Elasticsearch: Stores and indexes logs.
👉 Kibana: Provides a UI to search and analyze logs.

💡 Check logs of a pod:
kubectl logs <pod-name>
💡 Check logs of a pod running multiple containers:
kubectl logs <pod-name> -c <container-name>
💡 Stream logs in real-time:
kubectl logs -f <pod-name>
-----------------------------------------------------------------------------------------------------------------------------------------

12. How do you implement security measures within a Kubernetes cluster?

EXPLAIN IN THIS ANSWER:-
━━━━━━━━━━━━━━━━━━━━━━━━
1️⃣ RBAC (Role-Based Access Control) – Restricts user and service access based on roles.
2️⃣ Network Policies – Controls pod-to-pod and external communication, preventing unauthorized access within the cluster.
3️⃣ Container Security – Ensures containers are running securely by using image scanning tools (like Trivy).
4️⃣ Secrets Management – Stores sensitive data (like API keys and passwords), securely using Kubernetes Secrets 
   instead of plain text environment variables.
5️⃣ Audit Logging – Tracks all Kubernetes API activities, helping detect and respond to security incidents.
6️⃣ Update & Patching – Regularly updating Kubernetes components, nodes, and dependencies to prevent vulnerabilities.

🔹 "These measures provide a solid foundation for securing Kubernetes clusters."
-----------------------------------------------------------------------------------------------------------------------------------------
13. Explain Kubernetes RBAC?

EXPLAIN IN THIS ANSWER:-
━━━━━━━━━━━━━━━━━━━━━━━━
👉 "RBAC (Role-Based Access Control) in Kubernetes restricts access to resources based onuser roles.
    You define Roles with specific permissions (e.g., create, delete) and bind them to users or groups using RoleBindings.

👉  RBAC ensures users and applications have access only to necessary resources, 
    following the principle of least privilege and enhancing security."
-----------------------------------------------------------------------------------------------------------------------------------------

14. What is a Helm Chart, and how does it facilitate application deployment in Kubernetes?

EXPLAIN IN THIS ANSWER:-
━━━━━━━━━━━━━━━━━━━━━━━━
👉 "A Helm Chart is a package that contains all the Kubernetes resources needed to deploy an application, 
    such as Deployments, Services, and ConfigMaps. 

👉 It simplifies the process by allowing you to deploy an entire application with a single command. 

👉 Helm charts can be customized with a values.yaml file, like replicas, resource limits, etc,,.
    and they support versioning, making it easy to manage updates and rollbacks of applications in Kubernetes."
-----------------------------------------------------------------------------------------------------------------------------------------

15. How does Kubernetes use custom namespaces to organize cluster resources?

EXPLAIN IN THIS ANSWER:-
━━━━━━━━━━━━━━━━━━━━━━━━
👉 "In Kubernetes, namespaces are used to organize and isolate resources within a cluster. 

👉 They provide a way to divide cluster resources into different environments, teams, or applications.

👉 This makes it easier to manage and maintain your resources within the cluster,
   and also provides better security and resource isolation, while ensuring they don’t interfere with each other."
-----------------------------------------------------------------------------------------------------------------------------------------

16. What are liveness and readiness probes in Kubernetes, and how are they used?

EXPLAIN IN THIS ANSWER:-
━━━━━━━━━━━━━━━━━━━━━━━━
🔹 Liveness Probe:
👉 Liveness Probe checks if the container is still running. If it fails, the container will be restarted.

👉 You can set up a liveness probe to check if your app responds on a specific endpoint (like /healthz),
   if the app doesn’t respond correctly, Kubernetes will restart it.
✅ Example: Liveness Probe with HTTP Check:
---
livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
  initialDelaySeconds: 5
  periodSeconds: 10

👉 Kubernetes sends an HTTP GET request to /health every 10 seconds.
👉 If it fails, the pod is restarted.

🔹 Readiness Probe:
👉 Readiness Probe checks if the container is ready to handle traffic. If it fails, Kubernetes will stop routing traffic to that pod.
👉 A readiness probe can be configured to check if the database is ready before allowing the app to accept traffic.
✅ Example: Readiness Probe with HTTP Check
---
readinessProbe:
  httpGet:
    path: /readiness
    port: 8080
  initialDelaySeconds: 10
  periodSeconds: 15

👉 If /ready endpoint fails, the pod is temporarily removed from the Service.
👉 Once healthy again, Kubernetes adds it back.
-----------------------------------------------------------------------------------------------------------------------------------------

17. What is a Kubernetes network policy, and how does it work?

EXPLAIN IN THIS ANSWER:-
━━━━━━━━━━━━━━━━━━━━━━━━
👉 "A Kubernetes Network Policy controls pod-to-pod and external traffic, similar to a firewall. 
    By default, all pods can communicate, but network policies restrict traffic using rules based on pod labels and IP ranges. 
    This enhances security and isolates workloads."

🔹 Key Concepts
1️⃣ Default Behavior (Before Network Policies)
👉 By default, Kubernetes allows all pod-to-pod communication within a cluster.
👉 No restrictions unless you explicitly configure them.

2️⃣ Purpose of Network Policies
👉 To restrict traffic to specific pods or services.
👉 Enhance security by controlling which pods can talk to each other.

3️⃣ How It Works
👉 A network policy defines a set of rules that allow or deny traffic to/from pods based on labels, namespaces, ports, and IP blocks.
👉 If a policy is applied, it restricts traffic to only what is allowed by the policy and blocks anything not explicitly allowed.

4️⃣ Network Policy Selector
👉 PodSelector: Selects the pods that are affected by the policy (e.g., all pods with label app: frontend).
👉 Ingress and Egress Rules: Controls incoming and outgoing traffic.

🔹 Types of Network Policies:-
👉 Ingress Policies: Controls incoming traffic to a pod.
👉 Egress Policies: Controls outgoing traffic from a pod.
-----------------------------------------------------------------------------------------------------------------------------------------

18. What is the difference between a Kubernetes Deployment and a DaemonSet?

EXPLAIN IN THIS ANSWER:-
━━━━━━━━━━━━━━━━━━━━━━━━
🔹 Kubernetes Deployment:
👉 Purpose: Manages a replicated application that needs to run in multiple pods for scalability and high availability.
👉 Behavior: Ensures that a specified number of replicas of a pod are running at any given time. 
   It provides automated rollouts, scaling, and rollback capabilities.
👉 Ideal for stateless applications where you want multiple copies of your app running for high availability.

🔹 Kubernetes DaemonSet
👉 Purpose: Ensures that a copy of a pod is running on every node (or a subset of nodes) in the cluster.
👉 Behavior: Automatically creates a pod on each node in the cluster, ensuring that a single instance of the pod runs on each node.
👉 No scaling involved — there will always be one pod per node.

👉 "A Kubernetes Deployment ensures a specified number of replicas of a pod are running, ideal for stateless applications." 
👉 "A DaemonSet ensures that a pod runs on every node in the cluster, making it ideal for system-level tasks like monitoring or logging."
-----------------------------------------------------------------------------------------------------------------------------------------

19. How does ingress help in Kubernetes?

EXPLAIN IN THIS ANSWER:-
━━━━━━━━━━━━━━━━━━━━━━━━
👉 "Ingress in Kubernetes is used to manage external access to the services inside the cluster, typically HTTP/S traffic. 
   It provides features like load balancing, SSL termination, and path-based or host-based routing. 
   Ingress helps simplify service exposure by providing a single entry point and managing traffic routing efficiently, 
   improving scalability and security in your cluster."
-----------------------------------------------------------------------------------------------------------------------------------------

20. What is a Kubernetes Custom Resource Definition (CRD), and how can it be used to extend Kubernetes functionality?

EXPLAIN IN THIS ANSWER:-
━━━━━━━━━━━━━━━━━━━━━━━━
👉 "A Kubernetes Custom Resource Definition (CRD) allows you to define custom resources in your cluster, 
   extending Kubernetes with new resource types. 
   CRDs are commonly used with controllers or operators to automate complex tasks and manage application-specific resources.
   This gives you the flexibility to build Kubernetes-native solutions for your needs, 
   while maintaining the benefits of Kubernetes' declarative configuration and scalability."
-----------------------------------------------------------------------------------------------------------------------------------------

21. What is the purpose of Operators?

EXPLAIN IN THIS ANSWER:-
━━━━━━━━━━━━━━━━━━━━━━━━
👉 "A Kubernetes operator is a method of packaging, deploying, and managing a Kubernetes application.
   An operator uses the Kubernetes API to automate tasks such as deployment,
   scaling, implementing custom controllers, enabling self-healing systems, and supporting declarative management practices."

👉 "For example, the Prometheus Operator automates the deployment and management of
   Prometheus monitoring instances on Kubernetes, handling tasks such as configuration,
   scaling, and self-healing, thereby simplifying the monitoring of Kubernetes clusters."

-----------------------------------------------------------------------------------------------------------------------------------------

22. You have a Kubernetes pod that is stuck in CrashLoopBackOff . How do you diagnose and fix it?

EXPLAIN IN THIS ANSWER:-
━━━━━━━━━━━━━━━━━━━━━━━━
1. Check pod logs to understand why it’s crashing:
👉 kubectl logs <pod-name> --previous
2. Describe the pod to get detailed information about its state and events:
👉 kubectl describe pod <pod-name>
3. Look for any error messages or failed container states in the logs. 
   Common issues include misconfigurations, missing files, or incorrect image versions.
4. Fix the issue based on the logs (e.g., fix environment variables, update the
   image, or modify the configuration) and then restart the pod.

   To restart the pod manually:
👉 kubectl delete pod <pod-name>
-----------------------------------------------------------------------------------------------------------------------------------------

23. You need to restrict access to a Kubernetes service based on labels. How do you achieve this?

EXPLAIN IN THIS ANSWER:-
━━━━━━━━━━━━━━━━━━━━━━━━
You can use Network Policies to restrict traffic based on pod labels. 
A network policy controls the communication between pods based on labels and namespaces.

Example of a NetworkPolicy that allows traffic only to pods with the label role=db in the same namespace:

apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
   name: allow-db
spec:
   podSelector:
      matchLabels:
         role: db
ingress:
- from:
   - podSelector:
       matchLabels:
         role: app

This policy allows only pods with the role=app label to communicate with pods labeled role=db.
Apply the network policy:
👉 kubectl apply -f networkpolicy.yaml
-----------------------------------------------------------------------------------------------------------------------------------------

24. You want to upgrade a deployment to a new version. How do you perform a rolling update in Kubernetes?

EXPLAIN IN THIS ANSWER:-
━━━━━━━━━━━━━━━━━━━━━━━━
Kubernetes supports rolling updates by default when you update a Deployment.
To upgrade to a new version, simply update the deployment’s container image.

1. Update the image version in the deployment YAML:
apiVersion: apps/v1
kind: Deployment
metadata:
   name: my-app
spec:
   replicas: 3
   selector:
     matchLabels:
       app: my-app
   template:
     metadata:
      labels:
        app: my-app
     spec:
      containers:
      - name: my-app
        image: my-app:v2   ##### New version of the image #####
        ports:
        - containerPort: 80

2. Apply the update:
👉 kubectl apply -f deployment.yaml
Kubernetes will automatically perform a rolling update by replacing the old pods with the new ones without downtime.
-----------------------------------------------------------------------------------------------------------------------------------------

25. You want to increase the memory limit of a pod. How do you modify the pod's resource limits?

EXPLAIN IN THIS ANSWER:-
━━━━━━━━━━━━━━━━━━━━━━━━
To modify the resource limits (CPU/memory) for a pod, you need to update the resource requests and limits in the pod’s YAML definition.

Example modification:

apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  containers:
  - name: my-container
    image: nginx
   resources:
     requests:
       memory: "64Mi"
       cpu: "250m"
     limits:
       memory: "128Mi"
       cpu: "500m"

Apply the updated YAML:
👉 kubectl apply -f pod.yaml
To ensure the pod is restarted with the new limits, you can delete the pod or trigger a deployment update.
-----------------------------------------------------------------------------------------------------------------------------------------

26.  You want to limit the CPU and memory usage for a container. How do you set resource requests and limits?

EXPLAIN IN THIS ANSWER:-
━━━━━━━━━━━━━━━━━━━━━━━━
In the pod or container spec, you can define resource requests (minimum resources) and limits (maximum resources) for CPU and memory.
👉 Requests: Kubernetes uses these values to schedule the pod (ensures the pod gets enough resources).
👉 Limits: Kubernetes enforces these limits (pod will be killed if it exceeds them).

Example YAML:

apiVersion: v1
kind: Pod
metadata:
  name: resource-limited-pod
spec:
  containers:
    - name: my-container
      image: nginx
      resources:
        requests:
          memory: "256Mi"   ##### The container is guaranteed at least 256Mi of memory
          cpu: "250m"       ###### The container is guaranteed at least 0.25 CPU cores
        limits:
          memory: "512Mi"   ###### The container cannot use more than 512Mi of memory
          cpu: "500m"       ##### # The container cannot use more than 0.5 CPU cores
-----------------------------------------------------------------------------------------------------------------------------------------

27. You have a Kubernetes cluster with multiple worker nodes. One of the nodes becomes unresponsive and needs to be replaced. 
   Explain the steps you would take to replace the node without affecting the availability of applications running on the cluster?

EXPLAIN IN THIS ANSWER:-
━━━━━━━━━━━━━━━━━━━━━━━━
👉 "To replace an unresponsive Kubernetes node without downtime, I first drain the node to safely evict running pods. 
    Then, I delete the node from the cluster and provision a new node. 
    If using a cloud provider, Auto Scaling Groups can handle this automatically. 
    Finally, I add the new node back to the cluster and verify that workloads are running correctly. 
    This ensures high availability of applications without disruption."
-----------------------------------------------------------------------------------------------------------------------------------------

28. A Kubernetes pod is stuck in a "Pending" state. What could be the possible reasons, and how would you troubleshoot it?

EXPLAIN IN THIS ANSWER:-
━━━━━━━━━━━━━━━━━━━━━━━━
👉 "If a Kubernetes pod is stuck in 'Pending', I start by describing the pod to check events. 
    The most common issues are insufficient node resources, scheduling constraints, storage issues, or networking problems. 
    I check for resource limits, taints, node affinity rules, and persistent volume claims. 
    If it's an image pull issue, I verify registry access. 
    Based on the findings, I take appropriate actions to resolve the issue and ensure the pod gets scheduled."
-----------------------------------------------------------------------------------------------------------------------------------------

29.  You have a Kubernetes Deployment with multiple replicas, and some pods arefailing health checks. 
     How would you identify the root cause and fix it?

EXPLAIN IN THIS ANSWER:-
━━━━━━━━━━━━━━━━━━━━━━━━
👉 "If some Kubernetes pods are failing health checks, I start by describing the pod to check liveness and readiness probe failures. 
    Then, I review container logs for errors, manually test the health check endpoints, and verify resource limits. 
    If needed, I adjust the probe timing, ensure dependent services are available, and check for node issues. 
    This structured approach helps quickly identify and fix the root cause."
-----------------------------------------------------------------------------------------------------------------------------------------








