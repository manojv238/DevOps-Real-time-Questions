1. "Transition from Monolithic to Microservices" 
   Consider a company build some kind of monolithic architecture that handles a lot of products okay,
   now company is expanding and today industry is scalling so companies is expanding and then,
   monolithic architecture started causing problems so how do you think the company should shift it from
   monolithic to microservices and how to do deploy their containers and how can they implement kubernetes in it?

EXPLAIN IN THIS ANSWER:-
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ‘‰ Monolithic Architecture is Everything built a single unit(code base), tightly coupled like different application(front-end,backend,DB)
   run as single code base.
   Itâ€™s simple to develop but hard to scalability â€”any change requires again will do redeploying the entire system.

ğŸ‘‰ Microservices Architecture breaks the application into independent services, 
   each handling a specific function and communicating via APIs. 
   Each service can be deployed, scaled, and updated separately, making it more flexible and better fault isolation.
------------------------------------------------------------------------------------------------------------------------------------------

2. "Can you explain the Overview of Kubernetes Architecture"

EXPLAIN IN THIS ANSWER:-
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ‘‰ Kubernetes mainly consists of two components we can say one is MASTER NODE and second one is WORKER NODE.
   so in masternode inside there are four components..., So by the name we can understood from CM it is master node so it is 

1.Kube controller manager --> Manages the multiple process which are running masternode adn it is combined all the process together
                              and let in inform the MasterNode thats wt happening so it's basically manages all the process.

2.kube API-Server         --> Its acts as front end of MasterNode so it exposes all the API of k8s to MasterNode component and
                              is responsible for like creating communication between MasterNode and WorkerNode.

3.kube scheduler          --> Schedules like work for the WorkerNode as it inside MasterNode so it will schedule work for 
                              different WorkNodes.

4.etcd (database)         --> It's basically Key-Values to store like (username&password) so if we have to store it in this inside k8s
                              then we will mainly store it inside ETCD. 
                          ---> Okay these are 4 components which are MasterNode.

And comes into WokerNode inside there are two components..,

1.Kubelet     --> The Kubelet on that Worker Node communicates with the API Server to ensure the Pods are running.

2.Kube-Proxy  --> Kube Proxy ensures networking and allows to communication between Pods and Services.
              ---> So this the basic k8s architeture.
-----------------------------------------------------------------------------------------------------------------------------------------

3. "Comparison between Kubernetes and Docker Swarm for container orchestration".

EXPLAIN IN THIS ANSWER:-
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ‘‰ "Kubernetes and Docker Swarm are both container orchestration tools, but they different in complexity, scalability, and automation".

1. Kubernetes is a powerful orchestration tool and It will automatically self-healing, automated scaling, and advanced networking,
   making it perfect for large applications that need reliability and automation.

2.Docker Swarm is lightweight and easy to set up,it offers great for quick and simple deployments, 
  but it doesnâ€™t have the advanced automation and self-healing that compared to Kubernetes.
-----------------------------------------------------------------------------------------------------------------------------------------

4. What methods are available to expose Kubernetes services to external users, and how do they differ?

EXPLAIN IN THIS ANSWER:-
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ‘‰ In Kubernetes, a Service is a way to expose and manage network access to a set of Pods.

ğŸ‘‰ Pods are temporary and (they can be created and destroyed frequently), Services provide a stable way to communicate between applications.

There are four main types of services:

1ï¸âƒ£ ClusterIP (Default) â€“ Used for internal communication within the cluster.
2ï¸âƒ£ NodePort            â€“ Exposes services externally on a fixed port of each Node.
3ï¸âƒ£ LoadBalancer        â€“ Uses a cloud providerâ€™s load balancer(AWS) to distribute external traffic with a public IP.
4ï¸âƒ£ ExternalName        â€“ Maps to an external service (e.g., AWS RDS, external APIs)."one domain to another domain"
-----------------------------------------------------------------------------------------------------------------------------------------

5. How would you deploy an application in Kubernetes to ensure zero downtime during updates?

EXPLAIN IN THIS ANSWER:-
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… "To ensure zero downtime while updating an application in Kubernetes,
   I would use a Rolling Update strategy with Deployments". Hereâ€™s how it works and steps to explain:

1ï¸âƒ£ Define a Deployment with a specified replica count to ensure multiple pods are running.
2ï¸âƒ£ Use RollingUpdate strategy (default for Deployments) to gradually replace old pods with new ones.
3ï¸âƒ£ Set maxUnavailable=0 (ensures at least the current number of replicas remain available).
4ï¸âƒ£ Set maxSurge=1 or more (allows extra pods to start before terminating old ones).
5ï¸âƒ£ Use Readiness Probes to ensure new pods are only added to the service when theyâ€™re fully ready.
6ï¸âƒ£ Use Liveness Probes to monitor pod health and prevent serving broken pods.
7ï¸âƒ£ If an update fails, I can quickly rollback the deployment using:
ğŸ‘‰ kubectl rollout undo deployment <deployment-name>
ğŸ’¡ Example Deployment:
strategy:
  type: RollingUpdate
  rollingUpdate:
    maxUnavailable: 0
    maxSurge: 1
ğŸ”¥ "This ensures that users never experience downtime during updates!"
-----------------------------------------------------------------------------------------------------------------------------------------

6. Can you explain the difference between stateful and stateless applications, and how each is managed in Kubernetes?

EXPLAIN IN THIS ANSWER:-
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
In Kubernetes, applications can be either stateless or stateful,
and they are managed differently based on their data handling requirements.

ğŸ”¹ Stateless Applications:
ğŸ‘‰ Stateless applications are ones that donâ€™t need to remember anything from one request to the next request. 
   Each request is completely independent. So, once a request is finished, all the data is discarded. 
   For example, like (web servers"NGINX,APACHE" or APIs services), where the server doesn't need to remember previous interactions. 
   In Kubernetes, we manage these with Deployments because we can easily scale themâ€”if one pod fails, 
   it can be replaced without any issues. The new pod doesnâ€™t need to know about the old one.

ğŸ”¹ Stateful Applications:
ğŸ‘‰ Stateful applications, on the other hand, need to remember data between requests. 
   So, even if the pod is restarted, it should still have access to its previous data. 
   Examples include databases (e.g., MySQL, MongoDB), message queues, and other systems that maintain state between requests. 
   In Kubernetes handles these using StatefulSets, which ensures each pod gets a unique identity, 
   and we can attach persistent storage (like Persistent Volumes) so the data doesnâ€™t get lost. 
   This makes sure that even if the pod restarts, it can still find the same data.

ğŸ’¡ In simple terms:
ğŸ‘‰ Stateless apps donâ€™t store data between requests and are handled by Deployments.
ğŸ‘‰ Stateful apps store data and need StatefulSets and persistent storage to function properly.
-----------------------------------------------------------------------------------------------------------------------------------------

7. How do you handle persistent data in Kubernetes, and what are Persistent Volumes (PVs) and Persistent Volume Claims (PVCs)?

EXPLAIN IN THIS ANSWER:-
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"In Kubernetes, when we need to store data that should not be lost even if a pod restarts, 
we use Persistent Volumes (PVs) and Persistent Volume Claims (PVCs).

ğŸ”¹ Persistent Volume (PV) â€“ A storage resource in the cluster that is provisioned by an admin or dynamically created. 
   It acts like a hard drive that Kubernetes can use.

ğŸ”¹ Persistent Volume Claim (PVC) â€“ A request made by a pod to use storage resource. 
   The pod doesnâ€™t directly ask for a disk; instead, it asks for a PVC, and Kubernetes matches it with an available PV.

How Persistent Storage Works in Kubernetes:
1ï¸âƒ£ Create a PV â€“ Defines storage (e.g., EBS in AWS, NFS, Ceph, etc.).
2ï¸âƒ£ Create a PVC â€“ A pod requests storage by creating a claim.
3ï¸âƒ£ Pod uses the PVC â€“ Kubernetes binds the PVC to a suitable PV, and the pod gets persistent storage.
4ï¸âƒ£ Even if the pod restarts, the data remains because it is stored outside the pod.

ğŸ’¡ Example: Imagine a MySQL database running in Kubernetes. If the pod restarts without persistent storage, all data is lost. 
   But with a PVC attached to a PV, the database can retain its data across restarts.
   So, PVs provide actual storage, and PVCs let pods claim that storage. This ensures data persistence in Kubernetes!"
-----------------------------------------------------------------------------------------------------------------------------------------

8. Describe the process of scaling applications in Kubernetes both horizontally and vertically?

EXPLAIN IN THIS ANSWER:-
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"In Kubernetes, there are two ways to scale an application: Horizontally and Vertically".

1ï¸âƒ£ Horizontal Scaling (Scaling Out/In):
ğŸ‘‰ This means adding or removing pods to handle varying loads.
ğŸ‘‰ Kubernetes does this automatically using the Horizontal Pod Autoscaler (HPA).
ğŸ‘‰ HPA monitors metrics like CPU or memory usage and scales pods up or down as needed.

ğŸ’¡ Example command to manually scale:
kubectl scale deployment my-app --replicas=5
ğŸ’¡ Example HPA configuration:
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: my-app-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: my-app
  minReplicas: 2
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        targetAverageUtilization: 70

2ï¸âƒ£ Vertical Scaling (Scaling Up/Down):
ğŸ‘‰ This means increasing or decreasing CPU/RAM for existing pods instead of adding more pods.
ğŸ‘‰ Managed by Vertical Pod Autoscaler (VPA).
ğŸ‘‰ It adjusts resource requests/limits dynamically based on workload needs.

ğŸ’¡ Example VPA configuration:
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: my-app-vpa
spec:
  targetRef:
    apiVersion: "apps/v1"
    kind: "Deployment"
    name: "my-app"
  updatePolicy:
    updateMode: "Auto"
-----------------------------------------------------------------------------------------------------------------------------------------

9. What are ConfigMaps and Secrets in Kubernetes, and how are they used?

EXPLAIN IN THIS ANSWER:-
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"In Kubernetes, ConfigMaps and Secrets are used to store configuration data separately from application code, 
 making applications more flexible and secure."

ğŸ”¹ ConfigMaps (For Non-Sensitive Data):
ğŸ‘‰ Stores non-sensitive configuration data such as environment variables, config files, or command-line arguments.
ğŸ‘‰ Helps keep applications configurable without changing container images.
ğŸ‘‰ Example use case: Storing database connection URLs, API keys (if not sensitive), or log levels.

ğŸ’¡ Example ConfigMap YAML:
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-config
data:
  database_url: "mysql://db-service:3306"
  log_level: "debug"

ğŸ’¡ Using a ConfigMap in a Pod:
env:
  - name: DATABASE_URL
    valueFrom:
      configMapKeyRef:
        name: my-config
        key: database_url

ğŸ”¹ Secrets (For Sensitive Data)
ğŸ‘‰ Stores confidential data like passwords, API keys, TLS certificates.
ğŸ‘‰ Data is base64-encoded (not encrypted, so use RBAC to protect it).
ğŸ‘‰ Example use case: Storing database passwords, authentication tokens, or SSH keys.

ğŸ’¡ Example Secret YAML:
apiVersion: v1
kind: Secret
metadata:
  name: my-secret
type: Opaque
data:
  db_password: cGFzc3dvcmQ=   # (base64 encoded "password")

ğŸ’¡ Using a Secret in a Pod:
env:
  - name: DB_PASSWORD
    valueFrom:
      secretKeyRef:
        name: my-secret
        key: db_password
-----------------------------------------------------------------------------------------------------------------------------------------

10. How can you perform a rollback of a failed deployment in Kubernetes?

EXPLAIN IN THIS ANSWER:-
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"In Kubernetes, if a deployment update fails, we can easily roll back to a previous stable version using kubectl rollout undo."

ğŸ”¹ Steps to Perform a Rollback
1ï¸âƒ£ Check the Deployment History
ğŸ‘‰ kubectl rollout history deployment <deployment-name>
ğŸ’¡ This shows the revision history of the deployment.

2ï¸âƒ£ Rollback to the Previous Version
ğŸ‘‰ kubectl rollout undo deployment <deployment-name>
ğŸ’¡ This reverts the deployment to the last working state.

3ï¸âƒ£ Rollback to a Specific Revision (if needed)
ğŸ‘‰ kubectl rollout undo deployment <deployment-name> --to-revision=2
ğŸ’¡ This allows you to roll back to a specific version from the history.

4ï¸âƒ£ Check the Status After Rollback
ğŸ‘‰ kubectl get pods
ğŸ‘‰ kubectl describe deployment <deployment-name>
ğŸ’¡ Ensure the rollback was successful and pods are running correctly.

ğŸ”¹ Example Use Case:-
"Imagine you deployed a new version of an application, but it caused downtime. 
 Instead of debugging immediately, you quickly roll back to the previous working version to restore service, 
 then troubleshoot the issue separately."
" It helps maintain high availability and quick recovery from failures."
-----------------------------------------------------------------------------------------------------------------------------------------


























